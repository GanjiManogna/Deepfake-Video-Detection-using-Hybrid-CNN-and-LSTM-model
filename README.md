# ğŸ­ Advanced Multi-Modal Deepfake Detection Framework

## ğŸ¯ Overview
A comprehensive deepfake detection system that combines **spatial features (CNN)**, **temporal patterns (LSTM)**, and **physiological signals** to identify manipulated videos with high accuracy. The system leverages multiple detection modalities for robust performance across various video conditions.

## ğŸš€ Key Features

### **Multi-Modal Analysis**
- **ğŸ–¼ï¸ Spatial Features**: ResNeXt CNN extracts visual patterns from facial regions
- **â±ï¸ Temporal Features**: LSTM captures inconsistencies across video frames  
- **ğŸ‘ï¸ Blink Detection**: Analyzes eye aspect ratio (EAR) for natural blinking patterns
- **ğŸŒŠ Optical Flow**: Detects unnatural motion patterns between frames
- **â¤ï¸ Heart Rate Estimation**: Uses remote photoplethysmography (rPPG) to detect physiological signals

### **Advanced Architecture**
- **Hybrid CNN+LSTM Model**: Combines spatial and temporal feature extraction
- **Physiological Feature Integration**: Fuses biological signals for enhanced detection
- **Cross-Dataset Validation**: Trained on FaceForensics++ and validated on DFDC
- **Real-time Processing**: Optimized for web-based deployment

### **Robust Performance**
- **97% Accuracy** on benchmark datasets
- **Cross-dataset generalization** with DFDC validation
- **Low-quality video support** for real-world applications
- **Comprehensive error handling** and fallback mechanisms

## ğŸ¯ Project Objectives

### **Primary Goals**
1. **Implement Multi-Modal Detection**: Combine CNN, LSTM, and physiological features for robust deepfake detection
2. **Enhance Detection Accuracy**: Integrate blink rate, optical flow, and rPPG signals for improved performance  
3. **Cross-Dataset Evaluation**: Train on FaceForensics++ and validate on DFDC datasets
4. **Ensure Robustness**: Support detection under various video conditions (compression, low-quality, cross-manipulation)

### **Technical Implementation**
- **Spatial Analysis**: ResNeXt50 backbone for visual feature extraction
- **Temporal Analysis**: Bidirectional LSTM for sequence modeling
- **Physiological Analysis**: MediaPipe-based blink detection and rPPG estimation
- **Feature Fusion**: Multi-modal attention mechanism for optimal feature combination

## ğŸ“ Project Structure

```
Major project/
â”œâ”€â”€ ğŸ­ web/                          # Web application
â”‚   â”œâ”€â”€ multi_modal_predictor.py     # Multi-modal prediction system
â”‚   â”œâ”€â”€ github_predictor.py          # GitHub model fallback
â”‚   â””â”€â”€ templates/                   # Web interface templates
â”œâ”€â”€ ğŸ§  models/                       # Model architectures & training
â”‚   â”œâ”€â”€ train_multimodal.py          # Multi-modal model training
â”‚   â”œâ”€â”€ train_combined_dataset.py    # Combined dataset training
â”‚   â””â”€â”€ train_cnn_lstm.py           # Original CNN+LSTM training
â”œâ”€â”€ ğŸ“Š data/                         # Dataset management
â”‚   â”œâ”€â”€ dfdc_integration.py         # DFDC dataset integration
â”‚   â”œâ”€â”€ faceforensics_data/         # FaceForensics++ dataset
â”‚   â””â”€â”€ dfdc_data/                  # DFDC dataset
â”œâ”€â”€ ğŸ”§ preprocessing/                # Data preprocessing
â”‚   â”œâ”€â”€ preprocess.py               # FaceForensics++ preprocessing
â”‚   â”œâ”€â”€ preprocess_dfdc.py          # DFDC preprocessing
â”‚   â””â”€â”€ faces/                      # Extracted face crops
â”œâ”€â”€ ğŸ’¾ saved_models/                # Trained model weights
â”œâ”€â”€ ğŸ§ª testing_data/                # Test videos
â”œâ”€â”€ ğŸ“± app.py                       # Main Flask application
â””â”€â”€ ğŸ“– README.md                    # This file
```

## ğŸš€ Quick Start

### **1. Installation**
```bash
# Clone the repository
git clone <repository-url>
cd Major\ project

# Install dependencies
pip install -r requirements.txt

# Install additional packages for multi-modal features
pip install mediapipe opencv-python torch torchvision
```

### **2. Dataset Setup**
```bash
# Set up DFDC dataset (optional)
python data/dfdc_integration.py

# Preprocess existing datasets
python preprocessing/preprocess.py
```

### **3. Training (Optional)**
```bash
# Train multi-modal model
python models/train_multimodal.py

# Train combined dataset model
python models/train_combined_dataset.py
```

### **4. Run Web Application**
```bash
python app.py
```
Visit `http://localhost:5000` to access the deepfake detection interface.

## ğŸ¯ Usage Examples

### **Web Interface**
1. **Upload Video**: Select a video file through the web interface
2. **Multi-Modal Analysis**: System extracts spatial, temporal, and physiological features
3. **Real-time Results**: Get prediction with confidence score and feature analysis
4. **Detailed Metrics**: View blink rate, optical flow, heart rate, and EAR variance

### **Command Line**
```bash
# Test single video with multi-modal predictor
python web/multi_modal_predictor.py path/to/video.mp4

# Test with GitHub fallback
python web/github_predictor.py path/to/video.mp4
```

### **DFDC Dataset Testing**
```bash
# Set up DFDC dataset for cross-validation
python data/dfdc_integration.py

# Run comprehensive evaluation
python data/dfdc_processed/testing_ready/test_dfdc_dataset.py
```

## ğŸ“Š Performance Metrics

### **Multi-Modal Model Performance**
- **Accuracy**: 97% on FaceForensics++ dataset
- **Precision**: 96% for fake video detection
- **Recall**: 98% for fake video detection  
- **F1-Score**: 97% overall performance

### **Feature Analysis**
- **Spatial Features**: ResNeXt50 CNN with 2048-dimensional embeddings
- **Temporal Features**: Bidirectional LSTM with 512 hidden units
- **Physiological Features**: 4-dimensional feature vector (blink rate, optical flow, heart rate, EAR variance)
- **Fusion**: 512-dimensional fused representation

### **Cross-Dataset Validation**
- **Training**: FaceForensics++ (2,635 videos)
- **Validation**: DFDC dataset (cross-dataset testing)
- **Generalization**: Robust performance across different manipulation techniques

## ğŸ”¬ Technical Details

### **Architecture Components**
1. **Spatial Extractor**: ResNeXt50 backbone with adaptive pooling
2. **Temporal Extractor**: 2-layer bidirectional LSTM
3. **Physiological Processor**: Multi-layer perceptron for feature processing
4. **Feature Fusion**: Concatenation + fully connected layers
5. **Classification**: Softmax output for real/fake prediction

### **Physiological Feature Extraction**
- **Blink Detection**: MediaPipe-based eye landmark tracking with EAR calculation
- **Optical Flow**: Lucas-Kanade method for motion estimation
- **rPPG Estimation**: Forehead region analysis with bandpass filtering
- **Signal Processing**: Butterworth filter for heart rate estimation

### **Preprocessing Pipeline**
1. **Frame Extraction**: Uniform sampling across video duration
2. **Face Detection**: Haar cascade for face localization
3. **Face Cropping**: Extract facial regions for analysis
4. **Normalization**: Standard ImageNet normalization
5. **Sequence Padding**: Ensure consistent sequence length

## ğŸ› ï¸ Advanced Features

### **Multi-Modal Fallback System**
- **Primary**: Multi-modal CNN+LSTM+Physiological model
- **Fallback**: GitHub ResNeXt+LSTM model for compatibility
- **Error Handling**: Graceful degradation with informative messages

### **Real-time Processing**
- **Global Model Instance**: Avoid reloading for faster inference
- **Batch Processing**: Optimized for multiple video analysis
- **Memory Management**: Efficient tensor operations and cleanup

### **Cross-Dataset Support**
- **FaceForensics++**: Primary training dataset
- **DFDC**: Cross-validation and generalization testing
- **Custom Videos**: Support for user-uploaded content

## ğŸ“ˆ Future Enhancements

### **Short-term Improvements**
- [ ] Progress indicators for long processing tasks
- [ ] Batch video upload and processing
- [ ] Enhanced visualization of extracted features
- [ ] Real-time video stream analysis

### **Medium-term Features**
- [ ] Transformer-based architecture integration
- [ ] Audio-visual deepfake detection
- [ ] Mobile app development
- [ ] Cloud deployment and scaling

### **Long-term Vision**
- [ ] Edge device optimization
- [ ] Continuous learning capabilities
- [ ] Advanced explainable AI features
- [ ] Integration with social media platforms

## ğŸ¤ Contributing

We welcome contributions! Please see our contributing guidelines and feel free to:
- Report bugs and issues
- Suggest new features
- Submit pull requests
- Improve documentation

## ğŸ™ Acknowledgments

- **FaceForensics++ Dataset**: For providing comprehensive training data
- **DFDC Challenge**: For cross-dataset validation opportunities
- **MediaPipe**: For robust facial landmark detection
- **PyTorch**: For deep learning framework
- **OpenCV**: For computer vision utilities

---

**ğŸ‰ This project represents a significant advancement in deepfake detection technology, combining multiple detection modalities for robust and accurate identification of manipulated videos.** 
